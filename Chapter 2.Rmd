---
output: pdf_document
---

Experiment 1 of this chaper was included in Ngiam, Khaw, Holcombe and Goodbourn (2018), published in *Journal of Experimental Psychology: Learning, Memory and Cognition*.

## Abstract



## Introduction

A common method employed by visual working memory (VWM) researchers is manipulating the stimuli used in the change-detection task and examine the resulting effect on memory performance. A major point of contention central to the current debate over the architecture of VWM is the influence of stimulus complexity on VWM processes. Contrasting findings regarding the influence of stimulus complexity brought about two conflicting models of VWM architecture that have shaped much of the research, the *slots* model and the *resources* model. Defining complexity is difficult and varying metrics of complexity have likely contributed to different results. The experiments reported here introduce an objective estimate of stimulus complexity known as perimetric complexity. These experiments reveal that an overlooked influence on the VWM system and the complexity of a stimulus itself is the observers' familiarity with the stimulus. This chapter examines the influence of stimulus complexity and familiarity on two parameters of VWM, the encoding rate and capacity.

### Varying models of VWM architecture

Proponents of the *slots* model suggest the information capacity limit of VWM is defined strictly by the number of *objects* to be stored, regardless of the complexity of the stored items. In their seminal paper, @luck_capacity_1997 increased the stimulus complexity by adding relevant features where change could potentially occur in the to-be-remembered stimuli. They found change-detection performance was unchanged despite the increase in the number of relevant features. In their most striking result, when the stimuli were conjunctions of features from four dimensions (colour, orientation, size and the presence or absence of a gap), change-detection accuracy was equivalent when changes occurred in one dimension compared to when changes could occur in all dimensions and necessitates attention to all features of the stimulus. This result suggests the VWM system stores items with their features integrated, filling up a limited number of 'slots'.

On the other hand, proponents of the *resources* model suggest storing more complex objects expends additional limited resources, lowering overall VWM capacity.  @alvarez_capacity_2004 manipulated complexity by employing various stimlus sets, ranging from the more complex random polygons and Chinese characters to the simpler colour squares, in a change-detection task. @alvarez_capacity_2004 reported varying capacities for the different stimulus sets, a finding at odds with the *slots* model. Critically, they indexed each stimuli's complexity by conducting a visual search task with those stimuli. In the visual search task, observers had to locate a target object amongst an array of 4, 8 or 12 objects from the same stimulus class. They quantified complexity as the visual search rate, the additional time it took to find the target with each additional item in the search display. That is, the more complex objects produced increasingly slower visual search rates with larger search arrays. @alvarez_capacity_2004 found that the visual search rate was almost perfectly correlated with working memory capacity (*r* = -0.992). This finding that stimulus complexity not only influences but almost perfectly accounts for VWM performance motivated @alvarez_capacity_2004 to propose the *resources* model, which suggests that the VWM system allocates a finite pool of resources to storing stimuli. As more complex items require more resources, less items can be stored in VWM.

Although the object-based *slots* model [@luck_capacity_1997] and the feature-based "resources" model [@alvarez_capacity_2004] have been influential in VWM research, the manner in which object complexity influences VWM processes, the main difference that these models are predicated on, is still contended. Firstly, the results that these models are based upon have not been perfectly replicated. In their direct replication, @hardman_remembering_2015 were unable to reproduce Luck and Vogel's [-@luck_capacity_1997] most striking result where change detection accuracy for objects possessing features from four different dimensions was equal, regardless of which feature or the number of features the participants were required to remember. However, @hardman_remembering_2015 suggested that despite finding an effect of feature load on VWM performance, there was significant evidence to support that VWM capacity was constrained by an object load. This rules out the pure *slots* account where the number of items is the sole factor limiting VWM performance, but that the number of items is a significant contributor to the capacity limit of VWM.

Attempts at perfectly reproducing the findings of @alvarez_capacity_2004 have been similarly unsuccessful. @eng_visual_2005 were able to replicate the @alvarez_capacity_2004 finding that visual search rate negatively correlated with VWM capacity with various memory display presentations (500, 1000 ms and 3000 ms). However, they did not replicate the near perfect negative correlation found by @alvarez_capacity_2004, finding a weaker magnitude correlation (*r* = -.51) with 3000 ms memory display presentations. This suggests that complexity explains approximately 30% of the variation in VWM capacity, rather than all the variation as posited by the *resources* model. Additionally, @eng_visual_2005 found the visual search rates were better predictors of VWM capacities at shorter presentation durations compared to longer durations. If storage capacity was purely determined by the complexity of the stimulus, it should not be influenced by extended duration presentation. Thus, @eng_visual_2005 suggests that increased stimulus complexity limits perceptual encoding when items are being consolidated into VWM rather than overall VWM capacity.

@awh_visual_2007 suggest the differences in VWM capacity found by @alvarez_capacity_2004 were not due to stimulus complexity *per se* or perceptual encoding as suggested by @eng_visual_2005 but rather because of confusion at the comparison stage in change-detection. @awh_visual_2007 manipulated whether the changed object in the test array came from the same stimulus set (*within-category*) or from a different stimulus set (*cross-category*). Change-detection accuracy for *within-category* changes, such as a shaded cube changing to another shaded cube, decreased with increasing stimulus complexity, replicating the finding of @alvarez_capacity_2004. However when changes were *cross-category*, such as a shaded cube changing to a Chinese character, change-detection accuracy was equivalent to change-detection accuracy with simple colours. @jackson_similarity_2015 confirmed this finding by directly manipulating the visual similarity of the test object. They used contained sets of simple polygons and complex polygons and asked participants for subjective similarity ratings of polygon pairs within each set. They found change-detection accuracy decreased for complex polygons for test objects subjectively rated as similar, but no difference between simple and complex polygons when the test items were rated dissimilar. Therefore, as objects that were more complex were more visually similar (high *sample-test similarity*), within-category changes produced more errors made when detecting changes in the test array, lowering estimates of VWM capacity. The same visual mechanisms comparing highly similar stimuli that lead to lower estimates of VWM capacity are likely to contribute to slower visual search rates as well [@duncan_visual_1989], providing an explanation for the significant correlations between the two measures found by @alvarez_ccapacity_2004 and @eng_visual_2005.

It is still unclear whether effects of stimulus complexity on VWM are entirely attributable to sample-test similarity. The conclusions of @jackson_similarity_2015 rely on matched subjective ratings of simple polygon pairs and complex polygon pairs. It is not evident however whether a change of a simple polygon to another "similar" simple polygon is equivalently confusable to a change from a complex polygon to another "similar" complex polygon, despite being matched on subjective similarity ratings. Furthermore, @jackson_similarity_2015 report capacity estimates for both simple and complex polygons using dissimilar test items (approximately 1.5 items) that are far lower than equivalent estimates reported by @awh_visual_2007 (3.5 items for Chinese characters, 3.6 items for colours, 4.2 items for shaded cubes). These findings do not completely rule out Alvarez and Cavanagh's basic claim that VWM performance is influenced by stimulus complexity. For example, a more complex object may be represented at a lower resolution, with fewer intact features. A degraded representation of a complex object, such as a Chinese character, might be easily distinguishable from a coloured square, but not from another character with similar features. Prolonging encoding time may allow VWM representations of complex objects to have equivalent resolution and produce comparable estimates of VWM capacity for simple objects.

### Encoding rate

Like the capacity of VWM, the encoding rate of information into VWM is limited. The encoding rate was first quantified by @vogel_time_2006, who presented four colours for a fixed duration (100 ms) to observers in a change-detection task before interrupting encoding with a backward mask. @vogel_time_2006 varied the *stimulus onset asynchrony* (SOA), the duration before the onset of the backward mask available to encode durable representations into VWM. They found change-detection performance improved with longer encoding durations up to 200 ms, before plateauing. Each colour block took approximately 50 ms to encode prior to reaching an asymptote of approximately 2.5 object. 

Although the encoding rate reflects early VWM processing to create durable memory representations, it is often ignored by researchers despite the possibility that influences on early VWM processing might systematically limit VWM capacity estimates. Typically the time between memory and mask is kept constant throughout an experiment, but limiting encoding to brief durations may lead to underestimating VWM capacity. In our study, we adpoted the @vogel_time_2006 paradigm with various stimulus sets to examine whether the encoding rate is influenced by stimulus complexity. This allows us to determine whether a stimulus set with items containing more features (more complex) takes longer to encode into VWM. Increasing object complexity may slow the rate of encoding into VWM, such that complex objects will require more time to saturate VWM capacity. This would confound conclusions made from comparisons of VWM capacity for objects of different complexity with the same memory array durations, such as those found by @alvarez_capacity_2004.

### Defining complexity

Inconsistent definitions, measures and manipulations of complexity may have lead to the vastly differing models of VWM architecture. For example, @luck_capacity_1997 manipulated stimulus complexity by increasing the number of relevant features in the stimuli, whereas @alvarez_capacity_2004 varied stimulus sets and indexed complexity by measuring visual search slopes. In the present chapter, we defined stimulus complexity using *perimetric complexity*, the square of the combined inside and outside perimeters of a letter, divide by its area [@attneave_quantitative_1956]. There are many merits to using perimetric complexity to define stimulus complexity over previous manipulations and measures. Perimetric complexity has a nearly perfect negative linear relationship with letter identification efficiency, such that as letters increase in perimetric complexity, they are identified increasing inefficiently [@pelli_feature_2006]. @pelli_feature_2006 suggests this relationship occurs because complex letters require more features to be bound together, and perimetric complexity directly corresponds to the number of features. Perimetric complexity also provides an objective measure of complexity derived from the stimulus, that corresponds well to subjective figural goodness [@attneave_physical_1957] and apparent information load [@jiang_visual_2008; @makovski_indirect_2008]. An increase in perimetric complexity reflects an increase in stimulus complexity without the addition of extra feature dimensions. In the present study, we selected letters of the English alphabet and varied the perimetric complexity by presenting the letters in four different fonts (Experiment 1), as well as presented characters from four alphabets that were unfamiliar to our participants (Experiment 2).

### Familiarity

An additional factor that has been shown to influence consolidation and storage in VWM is familiarity. For example, chess experts showed an improved memory performance for chess game positions compared to novices, but equivalent memory performance when the chess pieces were random on the board [@chase_perception_1973]. More recently, higher VWM capacities have been found for famous faces over unfamiliar faces [@jackson_familiarity_2008], as well as for Pokémon (characters from a popular childhood cartoon) from an original generation over a recent generation only for those reporting familiarity with the characters [@xie_familiarity_2016]. Similarly, those familiar showed a higher encoding rate for Pokémon [@xie_familiarity_2017]. These studies do not directly control stimulus complexity and it is unknown whether these effects of familiarity are independent of stimulus complexity. 

While ingrained familiarity or expertise with the stimuli has consistently been shown to produce improvements in VWM performance, the results of training have been mixed. @olson_visual_2004 found no improvement in change detection of spatial locations across a 1 hour training session. 

Two noteworthy studies directly training stimulus familiarity were conducted by @chen_visual_2006 and @blalock_stimulus_2015. In @chen_visual_2006 observers were first trained to a subset of eight polygons. On each of 320 trials, a display containing four of the training set of poylgons were briefly presented. After a short blank delay, observers a polygon was presented at two of the locations at test. At one location the polygon remained unchanged, while at the other location, the polygon had changed to one of the remaining four in the training set that had not been initially presented. Observers were subsequently near perfect at recognising the trained polygon when presented a trained polygon and a novel polygon. However, this recognition familiarity did not translate to any improvements in change detection. @chen_visual_2006 

We examined this in Experiment 3, controlling for stimulus complexity by using the Brussels Artificial Character Set (BACS) [@vidal_bacs:_2017]. The BACS is designed to have the same number of junctions, strokes and terminations as English letters but is unfamiliar to the observer. Another critical aspect of the BACS characters is that they match the similarity between characters found with English letters [@vidal_bacs:_2017. Additionally, we matched the perimetric complexity of the BACS to the English letters. 



It is unclear how different qualities of the stimulus in terms of complexity, familiarity and similarity interact and contribute to VWM performance. The experiments presented in this chapter attempt to explicate the interaction by focusing primarily on familiarity.

## Modelling VWM performance

Encoding and capacity limits in VWM might best be described in terms of *objects*, as in the "slots" model or in terms of *features*, as in the "resources" model. If feature intergration limits the encoding rate into VWM, more complex letters will be encoded at a slower rate. If this is not the case, encoding rate will not vary with stimulus complexity. Similarly, if the number of features limits VWM capacity, fewer items will be stored from more complex alphabets. Otherwise, VWM capacity maybe be determined by the number of items, and will not vary with stimulus complexity. These models are shown in Figure 1.




